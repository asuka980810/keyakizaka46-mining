{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data  model  result  secret  tools\n"
     ]
    }
   ],
   "source": [
    "!ls /keyakizaka_mining/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import datetime\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Parameters\n",
    "\n",
    "PADDING = 0\n",
    "CONF_THRESHOLD = 0.5\n",
    "NMS_THRESHOLD = 0.4\n",
    "IMG_WIDTH = 416\n",
    "IMG_HEIGHT = 416\n",
    "\n",
    "# Default colors\n",
    "COLOR_BLUE = (255, 0, 0)\n",
    "COLOR_GREEN = (0, 255, 0)\n",
    "COLOR_RED = (0, 0, 255)\n",
    "COLOR_WHITE = (255, 255, 255)\n",
    "COLOR_YELLOW = (0, 255, 255)\n",
    "\n",
    "# path\n",
    "\n",
    "model_cfg = './cfg/yolov3-face.cfg'\n",
    "model_weights = '/keyakizaka_mining/model/yoloface/model-weights/yolov3-wider_16000.weights'\n",
    "\n",
    "image_dir = '/keyakizaka_mining/data/images/'\n",
    "face_dir = '/keyakizaka_mining/data/faceimages_pad%d'%(PADDING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "\n",
    "def get_outputs_names(net):\n",
    "    # Get the names of all the layers in the network\n",
    "    layers_names = net.getLayerNames()\n",
    "    return [layers_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "def refined_box(left, top, width, height):\n",
    "    right = left + width\n",
    "    bottom = top + height\n",
    "\n",
    "    original_vert_height = bottom - top\n",
    "    top = int(top + original_vert_height * 0.15)\n",
    "    bottom = int(bottom - original_vert_height * 0.05)\n",
    "\n",
    "    margin = ((bottom - top) - (right - left)) // 2\n",
    "    left = left - margin if (bottom - top - right + left) % 2 == 0 else left - margin - 1\n",
    "    right = right + margin\n",
    "\n",
    "    # padding\n",
    "    left -= PADDING\n",
    "    top -= PADDING\n",
    "    right += PADDING\n",
    "    bottom += PADDING\n",
    "    \n",
    "    return left, top, right, bottom\n",
    "\n",
    "def post_process(image_name, save_face_dir, frame, outs, conf_threshold, nms_threshold):\n",
    "    frame_height = frame.shape[0]\n",
    "    frame_width = frame.shape[1]\n",
    "\n",
    "    # Scan through all the bounding boxes output from the network and keep only the ones with high confidence scores.\n",
    "    # Assign the box's class label as the class with the highest score.\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > conf_threshold:\n",
    "                center_x = int(detection[0] * frame_width)\n",
    "                center_y = int(detection[1] * frame_height)\n",
    "                width = int(detection[2] * frame_width)\n",
    "                height = int(detection[3] * frame_height)\n",
    "                left = int(center_x - width / 2)\n",
    "                top = int(center_y - height / 2)\n",
    "                confidences.append(float(confidence))\n",
    "                boxes.append([left, top, width, height])\n",
    "\n",
    "    # Perform non maximum suppression to eliminate redundant overlapping boxes with lower confidences.\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold)\n",
    "    for i in indices:\n",
    "        box = boxes[i[0]]\n",
    "        left, top, width, height = box[0], box[1], box[2], box[3]     \n",
    "        if left < 0 or top < 0: continue\n",
    "        if left + width > frame.shape[1] or top + height > frame.shape[0]: continue\n",
    "        left, top, right, bottom = refined_box(left, top, width, height)\n",
    "        # cv2.imwrite( 'facetest_%d.png' % i[0], frame[top:bottom,left:right]) # save rectangle\n",
    "        cv2.imwrite( '%s/face%d_%s.png' % (save_face_dir, i[0], image_name), frame[top:bottom,left:right]) # save rectangle\n",
    "    return\n",
    "\n",
    "def save_detected_faceimages( image_path, image_name, save_face_dir ):\n",
    "    cap = cv2.VideoCapture( image_path )\n",
    "\n",
    "    has_frame, frame = cap.read()\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1 / 255, (IMG_WIDTH, IMG_HEIGHT), [0, 0, 0], 1, crop=False) # Create a 4D blob from a frame.\n",
    "\n",
    "    net.setInput(blob) # Sets the input to the network\n",
    "    outs = net.forward(get_outputs_names(net)) # Runs the forward pass to get output of the output layers\n",
    "\n",
    "    post_process(image_name, save_face_dir, frame, outs, CONF_THRESHOLD, NMS_THRESHOLD) # Remove the bounding boxes with low confidence\n",
    "\n",
    "    cap.release()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give the configuration and weight files for the model and load the network using them.\n",
    "\n",
    "net = cv2.dnn.readNetFromDarknet(model_cfg , model_weights)\n",
    "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
    "net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for member in os.listdir( image_dir ):\n",
    "    \n",
    "    print( member )\n",
    "    \n",
    "    blog_image_path = '%s/%s' % ( image_dir, member )\n",
    "    save_face_dir = '%s/%s' % ( face_dir, member )\n",
    "    if not os.path.exists( save_face_dir ): os.mkdir( save_face_dir )\n",
    "    \n",
    "    blog_images = os.listdir( blog_image_path )\n",
    "    for filename in blog_images:\n",
    "        image_path = '%s/%s' % ( blog_image_path, filename )\n",
    "        image_name = filename.split('.')[0] # ...\n",
    "        \n",
    "        save_detected_faceimages( image_path, image_name, save_face_dir )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
